{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAVAIL A FAIRE\n",
    "\n",
    "# 1- Importer les librairies necessaires\n",
    "# 2- Charger les images et les comvertir en dataframe\n",
    "# 3- \n",
    "# 4- Diviser les donnees pour le test et pour l'entrainnement\n",
    "# 5- Construire le modele d'entrainnement\n",
    "# 6- evaluer le modele\n",
    "# 7- Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Importer les librairies necessaires\n",
    "    # skimage de scikit-image pour le traitement d'image\n",
    "    # pandas pour la manipulation des donnees\n",
    "    # numpy pour les calcul mathematiques\n",
    "    # sklearn pour les bibliotheques de machine learning\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset d'entrainnement !!!\n",
      "chargement... categorie : cats\n",
      "cats chargee avec succes !!!!\n",
      "Dataset d'entrainnement !!!\n",
      "chargement... categorie : dogs\n",
      "dogs chargee avec succes !!!!\n"
     ]
    }
   ],
   "source": [
    "# 2- Charger les images et les comvertir en dataframe pour l'entainnement\n",
    "    # Nous utiliserons celui de cats vs dogs\n",
    "\n",
    "\n",
    "Categories = ['cats', 'dogs']\n",
    "flat_data_arr = []\n",
    "target_arr = []\n",
    "\n",
    "for i in Categories:\n",
    "    print(\"Dataset d'entrainnement !!!\")\n",
    "    print(f'chargement... categorie : {i}')\n",
    "    chemin = 'dataset/test_set/' + i\n",
    "    for img in os.listdir(chemin):\n",
    "        # lecture de l'image\n",
    "        img_array = imread(os.path.join(chemin, img))\n",
    "        # redimentionnement de la taille (pixel) avec 3 chaines de couleurs\n",
    "        img_resized = resize(img_array, (150, 150, 3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'{i} chargee avec succes !!!!')\n",
    "    \n",
    "flat_data = np.array(flat_data_arr)\n",
    "target = np.array(target_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 67501)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(flat_data)\n",
    "df['Target'] = target\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.02 GiB for an array with shape (8000, 67500) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# donnees en entree\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_train \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49miloc[:, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[0;32m      4\u001b[0m \u001b[39m#donnees en sortie\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_train \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1598\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1595\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1596\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[1;32m-> 1598\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    953\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    956\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    958\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1633\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1627\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m   1628\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1629\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using .loc for automatic alignment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1630\u001b[0m     )\n\u001b[0;32m   1632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m-> 1633\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1635\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   1636\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexing.py:1669\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1667\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1668\u001b[0m labels\u001b[39m.\u001b[39m_validate_positional_slice(slice_obj)\n\u001b[1;32m-> 1669\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_slice(slice_obj, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4144\u001b[0m, in \u001b[0;36mNDFrame._slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(slobj, \u001b[39mslice\u001b[39m), \u001b[39mtype\u001b[39m(slobj)\n\u001b[0;32m   4143\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[1;32m-> 4144\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mget_slice(slobj, axis\u001b[39m=\u001b[39;49maxis))\n\u001b[0;32m   4145\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[0;32m   4147\u001b[0m \u001b[39m# this could be a view\u001b[39;00m\n\u001b[0;32m   4148\u001b[0m \u001b[39m# but only in a single-dtyped view sliceable case\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\internals.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.internals.BlockManager.get_slice\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:898\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[0;32m    897\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 898\u001b[0m                 nb \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mtake_nd(taker, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, new_mgr_locs\u001b[39m=\u001b[39;49mmgr_locs)\n\u001b[0;32m    899\u001b[0m                 blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[0;32m    901\u001b[0m \u001b[39mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m    942\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[39m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m    946\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    949\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[39m#  these assertions\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m    952\u001b[0m     \u001b[39m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     \u001b[39m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Users\\Fg\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(out_shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.02 GiB for an array with shape (8000, 67500) and data type float64"
     ]
    }
   ],
   "source": [
    "# donnees en entree\n",
    "x_train = df.iloc[:, :-1]\n",
    "\n",
    "#donnees en sortie\n",
    "y_train = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Diviser les donnees pour le test et pour l'entrainnement\n",
    "\n",
    "# par definition le dataset d'origine a deja ete divise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5- Construction du modele d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition des parametres de grille pour GridSearchCv\n",
    "param_grid = {'C':[0.1, 1, 10, 100], 'gamma':[0.0001, 0.001, 0.1, 1], 'kernel':['rbf','poly']}\n",
    "\n",
    "# creation du classificateur suport vecteur\n",
    "svc = svm.SVC(probability=True)\n",
    "\n",
    "# creation du modele\n",
    "model = GridSearchCV(svc, param_grid)\n",
    "\n",
    "# entrainnement du modele\n",
    "model.fit(x_train, y_train)\n",
    "print('------- Model entrainne avec succes -------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6- Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge les donnees de test\n",
    "\n",
    "Categories = ['cats', 'dogs']\n",
    "flat_data_arr = []\n",
    "target_arr = []\n",
    "\n",
    "for i in Categories:\n",
    "    print(\"Dataset de test !!!\")\n",
    "    print(f'chargement... categorie : {i}')\n",
    "    chemin = 'dataset/test_set/' + i\n",
    "    for img in os.listdir(chemin):\n",
    "        # lecture de l'image\n",
    "        img_array = imread(os.path.join(chemin, img))\n",
    "        # redimentionnement de la taille (pixel) avec 3 chaines de couleurs\n",
    "        img_resized = resize(img_array, (150, 150, 3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'{i} chargee avec succes !!!!')\n",
    "    \n",
    "flat_data = np.array(flat_data_arr)\n",
    "target = np.array(target_arr)\n",
    "\n",
    "\n",
    "# on cree de dataframe\n",
    "df_test = pd.DataFrame(flat_data)\n",
    "df_test['Target'] = target\n",
    "df_test.shape\n",
    "\n",
    "# donnees en entree\n",
    "x_test = df_test.iloc[:, :-1]\n",
    "\n",
    "#donnees en sortie\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test du model\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# on determine la fiabilite du model\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(f'Le model est {accuracy*100}% fiable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rapport de classification\n",
    "print(classification_report(y_test, y_pred, target_names=['cat', 'dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7- Prediction\n",
    "\n",
    "chemin='dataset/test_set/dogs/dog.4001.jpg'\n",
    "img=imread(chemin)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img_resize=resize(img,(150,150,3))\n",
    "l=[img_resize.flatten()]\n",
    "probability=model.predict_proba(l)\n",
    "for ind,val in enumerate(Categories):\n",
    "    print(f'{val} = {probability[0][ind]*100}%')\n",
    "print(\" C'est un : \"+Categories[model.predict(l)[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
