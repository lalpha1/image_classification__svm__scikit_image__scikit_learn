{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lalpha1/image_classification__svm__scikit_image__scikit_learn/blob/master/classificateur_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **INF 3236: APPRENTISSAGE ARTIFICIEL 1**\n",
        "\n",
        "> TP3 SVM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X7pN1C4dl7cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **1.   Décrivons en nous appuyant sur la documentation de `Scikit Learn` les possibilités, option et paramètres d'utilisation des SVM.**\n",
        "\n"
      ],
      "metadata": {
        "id": "RZ1ECxjJkjhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les SVM (Support Vector Machines) sont une méthode populaire de classification supervisée et de régression. Scikit-learn est une bibliothèque populaire de Machine Learning en Python qui fournit une implémentation de SVM.\n",
        "\n",
        "Les SVM dans scikit-learn peuvent être utilisés pour la classification binaire (2 classes) et multiclasse (plus de 2 classes). Les paramètres et options d'utilisation des SVM dans scikit-learn incluent :\n",
        "\n",
        "1. `kernel`: Le noyau utilisé pour transformer les données d'entrée. Les noyaux disponibles incluent `linear` (linéaire), `poly` (polynomial), `rbf` (radial basis function) et `sigmoid`. La valeur par défaut est `rbf`.\n",
        "\n",
        "2. `C`: La valeur du paramètre de régularisation. Plus la valeur de C est élevée, plus l'algorithme est susceptible de mal classer les données d'entraînement, mais la marge est plus étroite. La valeur par défaut est 1.0.\n",
        "\n",
        "3. `gamma`: Le coefficient du noyau pour les noyaux `rbf`, `poly` et `sigmoid`. Une valeur élevée de gamma signifie que les points d'entraînement ont un impact plus important sur la décision frontière, ce qui peut conduire à un surapprentissage. La valeur par défaut est `auto`, ce qui signifie que `gamma` est calculé comme `1 / (n_features * X.var())`.\n",
        "\n",
        "4. `class_weight`: Les poids associés à chaque classe. Les valeurs peuvent être soit `balanced`, ce qui signifie que les poids sont inversément proportionnels au nombre d'échantillons dans chaque classe, soit un dictionnaire spécifiant explicitement les poids pour chaque classe.\n",
        "\n",
        "5. `decision_function_shape`: La forme de la fonction de décision. Pour la classification binaire, la valeur par défaut est `ovr` (One vs Rest) et pour la classification multiclasse, la valeur par défaut est `ovr` ou `ovo` (One vs One).\n",
        "\n",
        "6. `probability`: Si `True`, les prédictions de probabilité sont calculées à partir de la fonction de décision.\n",
        "\n",
        "7. `tol`: La tolérance pour la condition d'arrêt.\n",
        "\n",
        "8. `max_iter`: Le nombre maximum d'itérations autorisées.\n",
        "\n",
        "9. `random_state`: Le générateur de nombres aléatoires pour l'initialisation.\n",
        "\n",
        "Ces options et paramètres d'utilisation des SVM dans scikit-learn permettent aux utilisateurs de personnaliser le modèle pour répondre aux besoins spécifiques de leur tâche de classification ou de régression."
      ],
      "metadata": {
        "id": "NEcX--wykMqh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Etapes a suivre:\n",
        "\n",
        "\n",
        "1.  Importer les librairies necessaires\n",
        "2.  Charger les images \n",
        "3.  Créer le dataframe d'entrainement\n",
        "4.  Construire le modèle\n",
        "5.  Créer le dataframe de test\n",
        "6.  Evaluer le modèle\n",
        "7.  Effectuer des predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ww2GaapKmaoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "54GoMJHpZWWl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1- Importer les librairies necessaires\n",
        "# 2- Charger les images et les comvertir en dataframe\n",
        "# 3- \n",
        "# 4- Diviser les donnees pour le test et pour l'entrainnement\n",
        "# 5- Construire le modele d'entrainnement\n",
        "# 6- evaluer le modele\n",
        "# 7- Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f-obMk7YZWWp"
      },
      "outputs": [],
      "source": [
        "# 1- Importer les librairies necessaires\n",
        "    # os pour gerer les chemin\n",
        "    # zipfile pour dezipper les fichier\n",
        "    # skimage de scikit-image pour le traitement d'image\n",
        "    # pandas pour la manipulation des donnees\n",
        "    # numpy pour les calcul mathematiques\n",
        "    # sklearn pour les bibliotheques de machine learning\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DvbR_VNFit4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# telechargement des images\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FY2jI1-bIi6",
        "outputId": "c9473050-45fe-49e6-c047-93ff97ff2150"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-28 10:42:20--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.6.128, 108.177.112.128, 74.125.124.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.6.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   107MB/s    in 0.6s    \n",
            "\n",
            "2023-04-28 10:42:20 (107 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recuperation et dezippage des images\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref =  zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "JqObnOvBbv5s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZrTsz3-ZWWq",
        "outputId": "ab1374a0-e58a-4db9-bebb-c400a85f7520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset d'entrainnement !!!\n",
            "chargement... categorie : cats\n",
            "cats chargee avec succes !!!!\n",
            "Dataset d'entrainnement !!!\n",
            "chargement... categorie : dogs\n",
            "dogs chargee avec succes !!!!\n"
          ]
        }
      ],
      "source": [
        "# 2- Charger les images et les comvertir en dataframe pour l'entainnement\n",
        "    # Nous utiliserons celui de cats vs dogs\n",
        "\n",
        "\n",
        "Categories = ['cats', 'dogs']\n",
        "flat_data_arr = []\n",
        "target_arr = []\n",
        "\n",
        "for i in Categories:\n",
        "    print(\"Dataset d'entrainnement !!!\")\n",
        "    print(f'chargement... categorie : {i}')\n",
        "    chemin = '/tmp/cats_and_dogs_filtered/train/' + i\n",
        "    for img in os.listdir(chemin):\n",
        "        # lecture de l'image\n",
        "        img_array = imread(os.path.join(chemin, img))\n",
        "        # redimentionnement de la taille (pixel) avec 3 chaines de couleurs\n",
        "        img_resized = resize(img_array, (150, 150, 3))\n",
        "        flat_data_arr.append(img_resized.flatten())\n",
        "        target_arr.append(Categories.index(i))\n",
        "    print(f'{i} chargee avec succes !!!!')\n",
        "    \n",
        "flat_data = np.array(flat_data_arr)\n",
        "target = np.array(target_arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6n5wV6fZWWs",
        "outputId": "b569cb5a-e400-401d-a832-6b2a2dde0401"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 67501)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df = pd.DataFrame(flat_data)\n",
        "df['Target'] = target\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "10gUJl42ZWWt"
      },
      "outputs": [],
      "source": [
        "# donnees en entree\n",
        "#x_train = df.iloc[:, :-1]\n",
        "x = df.iloc[:, :-1]\n",
        "#donnees en sortie\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=77,stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fn2HvRIsZWWt"
      },
      "outputs": [],
      "source": [
        "# 4- Diviser les donnees pour le test et pour l'entrainnement\n",
        "\n",
        "# par definition le dataset d'origine a deja ete divise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw22CcI9ZWWu"
      },
      "outputs": [],
      "source": [
        "# 5- Construction du modele d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InXrp1QXZWWu"
      },
      "outputs": [],
      "source": [
        "# definition des parametres de grille pour GridSearchCv\n",
        "param_grid = {'C':[0.1, 1, 10, 100], 'gamma':[0.0001, 0.001, 0.1, 1], 'kernel':['rbf','poly']}\n",
        "\n",
        "# creation du classificateur suport vecteur\n",
        "svc = svm.SVC(probability=True)\n",
        "\n",
        "# creation du modele\n",
        "model = GridSearchCV(svc, param_grid)\n",
        "\n",
        "# entrainnement du modele\n",
        "model.fit(x_train, y_train)\n",
        "print('------- Model entraine avec succes -------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWsm9OAJZWWv"
      },
      "outputs": [],
      "source": [
        "# 6- Evaluation du modele"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnDOIqFXZWWv"
      },
      "outputs": [],
      "source": [
        "# on charge les donnees de test\n",
        "\n",
        "Categories = ['cats', 'dogs']\n",
        "flat_data_arr = []\n",
        "target_arr = []\n",
        "\n",
        "for i in Categories:\n",
        "    print(\"Dataset de test !!!\")\n",
        "    print(f'chargement... categorie : {i}')\n",
        "    chemin = '/tmp/cats_and_dogs_filtered/validation/' + i\n",
        "    for img in os.listdir(chemin):\n",
        "        # lecture de l'image\n",
        "        img_array = imread(os.path.join(chemin, img))\n",
        "        # redimentionnement de la taille (pixel) avec 3 chaines de couleurs\n",
        "        img_resized = resize(img_array, (150, 150, 3))\n",
        "        flat_data_arr.append(img_resized.flatten())\n",
        "        target_arr.append(Categories.index(i))\n",
        "    print(f'{i} chargee avec succes !!!!')\n",
        "    \n",
        "flat_data = np.array(flat_data_arr)\n",
        "target = np.array(target_arr)\n",
        "\n",
        "\n",
        "# on cree de dataframe\n",
        "df_test = pd.DataFrame(flat_data)\n",
        "df_test['Target'] = target\n",
        "df_test.shape\n",
        "\n",
        "# donnees en entree\n",
        "x_test = df_test.iloc[:, :-1]\n",
        "\n",
        "#donnees en sortie\n",
        "y_test = df_test.iloc[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3AzyLHbZWWw"
      },
      "outputs": [],
      "source": [
        "# test du model\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# on determine la fiabilite du model\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "print(f'Le model est {accuracy*100}% fiable')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saY2Ec_qZWWw"
      },
      "outputs": [],
      "source": [
        "# rapport de classification\n",
        "print(classification_report(y_test, y_pred, target_names=['cat', 'dog']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr4uRoYOZWWw"
      },
      "outputs": [],
      "source": [
        "# 7- Prediction\n",
        "\n",
        "chemin='/tmp/cats_and_dogs_filtered/validation/dog.2003.jpg'\n",
        "img=imread(chemin)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "img_resize=resize(img,(150,150,3))\n",
        "l=[img_resize.flatten()]\n",
        "probability=model.predict_proba(l)\n",
        "for ind,val in enumerate(Categories):\n",
        "    print(f'{val} = {probability[0][ind]*100}%')\n",
        "print(\" C'est un : \"+Categories[model.predict(l)[0]])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}